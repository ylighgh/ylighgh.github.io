=== Reptile

==== Requests
https://docs.python-requests.org/en/latest/[官方文档]

**导入Requests包**

```
improt requests
```

**模拟User-Agent**
```
headers = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36"
}
```

==== Re
https://www.runoob.com/regexp/regexp-syntax.html[正则表达式规则]

https://tool.oschina.net/regex#[正则表达式测试地址]


**Re匹配规则**

[NOTE]
====
- findall:匹配字符串中所有的符合正则的内容

- finditer:匹配字符串中所有的内容[返回的是迭代器],需要把它从迭代器中遍历出来,从迭代器中拿到内容需要.group()

- search:找到一个结果就返回,返回的结果是match对象,拿数据需要.group()

- match:从头开始匹配

====


**导入Requests包**

```
improt re
```

**定义匹配规则**
```
obj = re.compile(r".*?<ul>(?P<匹配的内容(自定义名称)>.*?)</ul>", re.S)  # re.S : 让.能匹配换行符
```

==== Bs4

https://www.crummy.com/software/BeautifulSoup/bs4/doc/[官方文档]

**BeautifulSoup**

```
from bs4 import BeautifulSoup
```

**将获取的源码交给bs处理**
```
soup = BeautifulSoup(resp.text, "html.parser") //指定html解析器
```

**从bs对象中查找数据**
[NOTE]
====
- find(标签，属性=值):匹配需要找的标签

- find_all:找到所以的标签

- get:获取对象中的属性值

- str:获取对象中的文本
====

==== Xpath

**Xpath**

```
from lxml import etree
```

TIP: Xpath是在XML文档中搜索内容的一门语言

**bilibilirank**
```
# 定义范围
li_list = html.xpath('//*[@id="app"]/div/div[2]/div[2]/ul/li')

for li in li_list:
    rank_num = li.xpath('./div[1]/text()')[0]
    rank_title = li.xpath('./div[2]/div[2]/a/text()')[0] //text:获取标签内的内容
    rank_href = li.xpath('./div[2]/div[2]/a/@href')[0] //@标签名：获取标签的属性
    # print(no,title,href.strip("//"))
    csvwriter.writerow([rank_num, rank_title, "https:" + rank_href])
```