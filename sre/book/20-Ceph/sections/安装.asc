=== 安装

.添加依赖
[source,bash]
----
yum -y install python-setuptools
----

.添加Ceph仓库
[source,bash]
----
CEPH_STABLE_RELEASE=nautilus

cat  << EOF > /etc/yum.repos.d/ceph.repo
[Ceph]
name=Ceph packages for \$basearch
baseurl=https://mirrors.aliyun.com/ceph/rpm-${CEPH_STABLE_RELEASE}/el7/\$basearch
enabled=1
gpgcheck=1
type=rpm-md
gpgkey=https://mirrors.aliyun.com/ceph/keys/release.asc

[ceph-noarch]
name=Ceph noarch packages
baseurl=https://mirrors.aliyun.com/ceph/rpm-${CEPH_STABLE_RELEASE}/el7/noarch
enabled=1
gpgcheck=1
type=rpm-md
gpgkey=https://mirrors.aliyun.com/ceph/keys/release.asc

[ceph-source]
name=Ceph source packages
baseurl=https://mirrors.aliyun.com/ceph/rpm-${CEPH_STABLE_RELEASE}/el7/SRPMS/
enabled=1
gpgcheck=1
type=rpm-md
gpgkey=https://mirrors.aliyun.com/ceph/keys/release.asc
EOF
----

.创建部署目录
[source,bash]
----
mkdir -p ~/ceph-cluster && cd ~/ceph-cluster
----

.安装ceph-deploy
[source,bash]
----
yum -y install ceph-deploy
----

.创建集群 
[source,bash]
----
ceph-deploy new node1 node2 node3 --public-network 10.0.2.0/24 --cluster-network 10.0.2.0/24
----

.安装ceph
[source,bash]
----
# 自动安装
ceph-deploy install node1 node2 node3

# 手动安装
yum -y install ceph ceph-radosgw 
----

.设置 MON 和 KEY
[source,bash]
----
ceph-deploy mon create-initial
----

TIP:: 说明：执行完成后会在部署目录 `~/ceph-cluster/`` 下生成以下 `keyring` 文件

- ceph.bootstrap-mds.keyring
- ceph.bootstrap-mgr.keyring
- ceph.bootstrap-osd.keyring
- ceph.bootstrap-rgw.keyring 
- ceph.client.admin.keyring

.将 ceph.client.admin.keyring 拷贝到各个节点上
[source,bash]
----
ceph-deploy --overwrite-conf admin node1 node2 node3
----

TIP:: 拷贝之后的文件在节点上的 `/etc/ceph/`

.安装MGR
[source,bash]
----
ceph-deploy mgr create node1 node2 node3
----

.启动OSD
[source,bash]
----
# 擦除硬盘
ceph-deploy disk zap node1 /dev/sdb
ceph-deploy disk zap node2 /dev/sdb
ceph-deploy disk zap node3 /dev/sdb

# 创建osd节点
ceph-deploy osd create node1 --fs-type xfs --data /dev/sdb
ceph-deploy osd create node2 --fs-type xfs --data /dev/sdb
ceph-deploy osd create node3 --fs-type xfs --data /dev/sdb
----

.修改ceph.conf
[source,bash]
----
cat << EOF >> ~/ceph-cluster/ceph.conf
mon_clock_drift_allowed = 2
mon_clock_drift_warn backoff = 30
EOF

ceph config set mon mon_warn_on_insecure_global_id_reclaim false
ceph config set mon mon_warn_on_insecure_global_id_reclaim_allowed false

ceph-deploy --overwrite-conf config push node{1,2,3}

systemctl restart ceph-mon.target
----

.验证
[source,bash]
----
[root@node1 ceph-cluster]# ceph -s
  cluster:
    id:     a7074991-7a98-42b1-a517-891782210587
    health: HEALTH_OK
 
  services:
    mon: 3 daemons, quorum node1,node2,node3 (age 22s)
    mgr: node1(active, since 2m), standbys: node2, node3
    osd: 3 osds: 3 up (since 119s), 3 in (since 119s)
 
  data:
    pools:   0 pools, 0 pgs
    objects: 0 objects, 0 B
    usage:   3.0 GiB used, 13 GiB / 16 GiB avail
    pgs:    
----

