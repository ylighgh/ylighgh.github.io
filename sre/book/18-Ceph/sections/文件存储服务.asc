=== 文件存储服务

.启用MDS服务
[source,bash]
----
ceph-deploy mds create node1 node2 node3
----

.创建文件存储池
建两个存储池，`cephfs_metadata` 用于存文件系统元数据，`cephfs_data` 用于存文件系统数据
[source,bash]
----
ceph osd pool create cephfs_metadata 32 32
ceph osd pool create cephfs_data 32 32

# 启用
ceph osd pool application enable cephfs_metadata cephfs
ceph osd pool application enable cephfs_data cephfs
----

.创建文件系统
[source,bash]
----
ceph fs new koenlifs cephfs_metadata cephfs_data
----

.验证挂载
[source,bash]
----
mkdir -p /ceph/cephfs 

# 方式一 mount
mount -t ceph node1:6789,node2:6789,node3:6789:/ /ceph/cephfs -o name=admin,secret=AQAZUhdj3ruKHhAAt5E5YdYhfGXUpnorM0VBDw==


# 方式二 ceph-fuse
yum -y install ceph-fuse

ceph-fuse -n client.admin -m node1:6789,node2:6789,node3:6789 /ceph/cephfs


[root@node2 cephfs]# df -h
Filesystem                                      Size  Used Avail Use% Mounted on
devtmpfs                                        988M     0  988M   0% /dev
tmpfs                                          1000M     0 1000M   0% /dev/shm
tmpfs                                          1000M  8.6M  991M   1% /run
tmpfs                                          1000M     0 1000M   0% /sys/fs/cgroup
/dev/mapper/centos-root                          17G  1.8G   16G  11% /
/dev/sda1                                      1014M  136M  879M  14% /boot
tmpfs                                           200M     0  200M   0% /run/user/0
tmpfs                                          1000M   52K 1000M   1% /var/lib/ceph/osd/ceph-1
10.0.2.10:6789,10.0.2.20:6789,10.0.2.30:6789:/  3.8G     0  3.8G   0% /ceph/cephfs
----

.取消挂载
[source,bash]
----
umount /ceph/cephfs
----

TIP:: secret 在 /etc/ceph/ceph.client.admin.keyring
